groups:
  - name: DeliveryControl
    rules:
      - alert: DeliveryControlAlert
        expr: rate(http_server_requests_seconds_count{uri="/startup-check", method="GET", instance="delivery-control:8081"}[10m]) > 0.15
        for: 5s
        labels:
          app: delivery-control
          severity: critical
          group: delivery-control
          env: production
          team: delivery-control
        annotations:
          titulo: "Muitas Consultas"
          descricao: "Esse recurso {{ $labels.instance }} está com muitas consultas ({{ $value }})"

# LATENCY
  - name: delivery-control-slack
    rules:
      - alert: 'QUEBRA DE SLO'
        # a expressão verifica se, nos últimos 1 minuto, pelo menos 50% das requisições HTTP da aplicação "delivery-control" (excluindo "/actuator/prometheus") estão abaixo do quantil 90 do tempo de resposta.
        expr: (histogram_quantile(0.90, sum(rate(http_server_requests_seconds_bucket{instance="delivery-control:8081", job="delivery-control",uri!="/actuator/prometheus"}[1m])) by (le))) >= 0.5
        for: 1m # tempo que a métrica deve permanecer como verdadeira para disparar o alerta
        labels: # labels utilizados pelo alertmanager
          app: 'delivery-control'
          severity: 'critical'
          group: 'delivery-control-slack'
          env: 'production'
          team: 'delivery-control-slack'
        annotations: # anotações recebidas pelo alertmanager e passadas para o target que nesse exmplo é o slack
          title: 'QUEBRA DE SLO'
          summary: '90% das requisições estão sendo atendidas a 500ms ou mais.'
          description: 'API DeliveryControl esta quebrando o SLO, 90% das requisições estão sendo atendidas em 500ms ou mais no último minuto.'
      - alert: 'REQUISIÇÕES ACIMA DE 5s'
        expr: rate(http_server_requests_seconds_sum{instance="delivery-control:8081", application="Delivery Control", uri!="/actuator/prometheus"}[1m])
          / rate(http_server_requests_seconds_count{instance="delivery-control:8081", application="Delivery Control", uri!="/actuator/prometheus"}[1m]) >= 5
        for: 1m # tempo que a métrica deve permanecer como verdadeira para disparar o alerta
        labels: # labels utilizados pelo alertmanager
          app: 'delivery-control'
          severity: 'critical'
          group: 'delivery-control-slack'
          env: 'production'
          team: 'delivery-control-slack'
        annotations: # anotações recebidas pelo alertmanager e passadas para o target que nesse exmplo é o slack
          title: 'REQUISIÇÕES ACIMA DE 5s'
          summary: 'Algumas requisições estão demorando mais de 5 segundos para responder.'
          description: 'Algumas requisições da applicação {{ $labels.instance }} estão demorando mais de 5 segundos para responder no ultimo minuto. Endpoint: {{$labels.uri}} | Tempo: {{ $value }}s'

# ERRORS
      - alert: 'ERRO 500'
        expr: (sum(rate(http_server_requests_seconds_count{job="delivery-control",status="500",uri!="/actuator/prometheus"}[1m])) / sum(rate(http_server_requests_seconds_count{job="delivery-control",uri!="/actuator/prometheus"}[1m]))) >= 0.01
        for: 1m
        labels:
          app: 'delivery-control'
          severity: 'critical'
          group: 'delivery-control-slack'
          env: 'production'
          team: 'delivery-control-slack'
        annotations:
          title: 'ERRO 500'
          summary: 'Erro 500 acima de 1% no último minuto.'
          description: 'API forum esta com taxa de erros 500 acima de 1% no último minuto'
#  THREADS
      - alert: TO MANY THREADS [WARNING]
        expr: sum(increase(jvm_threads_states_threads{application="Delivery Control", instance="delivery-control:8081", job="delivery-control", state="runnable"}[1m])) by (state) >= 100
        for: 1m
        labels:
          app: delivery-control
          severity: warning
          group: delivery-control-slack
          env: production
          team: delivery-control-slack
        annotations: # anotações recebidas pelo alertmanager e passadas para o target que nesse exmplo é o slack
          title: 'TO MANY THREADS WARNING'
          summary: 'Mais de 100 Threads sendo executadas'
          description: 'Mais de 100 Threads sendo executadas no ultimo minuto.'
      - alert: TO MANY THREADS [FIRING]
        expr: sum(increase(jvm_threads_states_threads{application="Delivery Control", instance="delivery-control:8081", job="delivery-control", state="runnable"}[1m])) by (state) >= 400
        for: 1m
        labels:
          app: delivery-control
          severity: critical
          group: delivery-control-slack
          env: production
          team: delivery-control-slack
        annotations: # anotações recebidas pelo alertmanager e passadas para o target que nesse exmplo é o slack
          title: 'TO MANY THREADS CRITICAL'
          summary: 'Mais de 400 Threads sendo executadas'
          description: 'Mais de 400 Threads sendo executadas no ultimo minuto.'
# CPU
      - alert: CPU UTILIZATION >= 90%
        expr: process_cpu_usage{application="Delivery Control", instance="delivery-control:8081", job="delivery-control"} >= 0.9
        for: 1m
        labels:
          app: delivery-control
          severity: critical
          group: delivery-control-slack
          env: production
          team: delivery-control-slack
        annotations: # anotações recebidas pelo alertmanager e passadas para o target que nesse exmplo é o slack
          title: 'CPU USAGE >= 90%'
          summary: 'JVM >= 90% de CPU'
          description: 'A  JVM da aplicação {{ $labels.instance }} está utilizando mais de 90% da CPU no ultimo minuto. Valor: {{ $value }}'
      - alert: CPU AVERAGE
        expr: system_load_average_1m{application="Delivery Control", instance="delivery-control:8081", job="delivery-control"} > system_cpu_count{application="Delivery Control", instance="delivery-control:8081", job="delivery-control"}
        for: 1m
        labels:
          app: delivery-control
          severity: critical
          group: delivery-control-slack
          env: production
          team: delivery-control-slack
        annotations: # anotações recebidas pelo alertmanager e passadas para o target que nesse exmplo é o slack
          title: 'CPU AVERAGE'
          summary: 'A utilização de CPU esta acima do limite'
          description: 'A utilização de CPU da aplicação {{ $labels.instance }} está acima do limite. Valor: {{ $value }}'
# HEAP USED
      - alert: HEAP USED >= 80%
        expr: sum(jvm_memory_used_bytes{application="Delivery Control", instance="delivery-control:8081", job="delivery-control", area="heap"})* 100 / sum(jvm_memory_max_bytes{application="Delivery Control", instance="delivery-control:8081", job="delivery-control", area="heap"}) > 80.0
        for: 1m
        labels:
          app: delivery-control
          severity: critical
          group: delivery-control-slack
          env: production
          team: delivery-control-slack
        annotations: # anotações recebidas pelo alertmanager e passadas para o target que nesse exmplo é o slack
          title: 'HEAP USED >= 80%'
          summary: 'Memória heap acima de 80%'
          description: 'A aplicação {{ $labels.instance }} está utilizando mais de 80% da memória heap no ultimo minuto. Valor: {{ $value }}'